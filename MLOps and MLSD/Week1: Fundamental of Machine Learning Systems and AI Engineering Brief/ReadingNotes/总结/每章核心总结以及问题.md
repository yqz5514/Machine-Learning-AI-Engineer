MLSD ch1.1
🔥 3 句话总结 Key Takeaways
1️⃣ 机器学习适用于 从数据中学习复杂模式并进行预测，而非精确计算或简单规则可以解决的问题。
2️⃣ 如果没有数据、问题无规律、或错误预测代价过高，ML 可能不是最佳选择。
3️⃣ ML 适用于大规模、重复性任务，并在数据模式变化时比传统规则系统更灵活，但仍需权衡成本和可解释性。

🔥 “如果面试官问我...” 的方式回顾
❓ 面试官问 1：什么时候应该使用机器学习？
✅ 回答：
机器学习适用于数据驱动的问题，即：

数据中存在可学习的模式（如 Airbnb 房价预测）。
手写规则难以应对复杂情况（如自动驾驶）。
可以对新数据泛化，预测未知情况。
❓ 面试官问 2：什么时候不适合使用机器学习？
✅ 回答：
ML 可能不是最佳选择的情况：

问题无规律可循（如掷骰子）。
已有简单规则可以解决（如计算 2+2）。
错误预测的成本太高（如医疗诊断，AI 错误可能导致误诊）。
❓ 面试官问 3：ML 比传统方法有什么优势？
✅ 回答：

ML 可以自动学习模式，而传统方法需要手动编写规则。
ML 适用于大规模数据，如搜索引擎优化，而规则系统难以扩展。
ML 可以适应变化，如个性化推荐系统，而手写规则需要不断更新。

Ch1.2
📌 Key Takeaways (3-Sentence Summary)
1️⃣ ML research focuses on SOTA performance, while production prioritizes speed, interpretability, and real-world constraints.
2️⃣ Latency is a critical metric in ML systems, with percentiles (p50,p95, p99) offering a more reliable measurement than mean latency.
3️⃣ Batch processing can increase inference latency, but is commonly used in large-scale distributed ML systems for efficiency.

📌 If an Interviewer Asks...
❓ Q1: Why is ML latency measurement important in production?
✅ Answer:
Latency affects user experience and system performance. Mean latency can be misleading, so high percentiles (e.g., p95) help detect outliers and ensure real-world system reliability.

❓ Q2: Why does ML in production prioritize interpretability?
✅ Answer:
Interpretability is essential for debugging, bias detection, and regulatory compliance. In high-stakes applications like loan approval and medical diagnosis, a black-box model is often unacceptable.

❓ Q3: How does batch processing affect ML inference?
✅ Answer:
Batching improves computational efficiency, but introduces higher latency, since the system must wait for enough queries before processing them.


AIE ch1.1
📌 Key Takeaways (3-Sentence Summary)
1️⃣ LLMs utilize self-supervised learning to process massive datasets, enhancing text-based AI applications.
2️⃣ Foundational Models extend AI beyond text, enabling multimodal processing (text, images, audio, and video).
3️⃣ To improve AI output, engineers leverage Prompt Engineering, RAG (retrieval-augmented generation), and fine-tuning.

📌 If an Interviewer Asks...
❓ Q1: How does an LLM differ from traditional language models?
✅ Answer:
Traditional LMs predict missing words (Masked LM) or generate text sequentially (Auto-regressive LM), whereas LLMs handle longer dependencies, generate coherent responses, and can engage in interactive dialogue.

❓ Q2: What is the advantage of Foundational Models over LLMs?
✅ Answer:
LLMs are text-only, whereas Foundational Models support multimodal inputs (text, images, audio, video), allowing AI to work across diverse domains like healthcare, robotics, and finance.

❓ Q3: How can an AI engineer improve a model’s performance?
✅ Answer:

Prompt Engineering (optimize inputs for better model outputs).
RAG (Retrieval-Augmented Generation) (integrate external knowledge for more accurate responses).
Fine-Tuning (train models on domain-specific data for better specialization).

AIE ch1.2 
📌 Key Takeaways (3-Sentence Summary)
1️⃣ Foundation models enable AI applications across diverse fields, including software development, content creation, customer service, and automation.
2️⃣ AI-powered tools significantly enhance productivity, particularly in writing, coding, image/video production, and information aggregation.
3️⃣ While AI offers incredible efficiency gains, ethical concerns (bias, misinformation, and automation risks) remain challenges that must be addressed.

📌 If an Interviewer Asks...
❓ Q1: What are the top use cases for Foundation Models in enterprises?
✅ Answer:
Foundation Models are widely used in coding, writing, customer service, and workflow automation, enabling organizations to reduce costs, improve efficiency, and optimize business processes.

❓ Q2: How is AI impacting software engineering jobs?
✅ Answer:
AI accelerates coding productivity but is less effective in highly complex tasks. It is expected to automate simple programming tasks while augmenting engineers rather than fully replacing them.

❓ Q3: What are the ethical concerns surrounding generative AI?
✅ Answer:
AI raises concerns about content authenticity, misinformation, bias, and automation-related job losses, requiring responsible AI governance and oversight.




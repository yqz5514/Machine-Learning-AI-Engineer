MLSD ch1.1
ğŸ”¥ 3 å¥è¯æ€»ç»“ Key Takeaways
1ï¸âƒ£ æœºå™¨å­¦ä¹ é€‚ç”¨äº ä»æ•°æ®ä¸­å­¦ä¹ å¤æ‚æ¨¡å¼å¹¶è¿›è¡Œé¢„æµ‹ï¼Œè€Œéç²¾ç¡®è®¡ç®—æˆ–ç®€å•è§„åˆ™å¯ä»¥è§£å†³çš„é—®é¢˜ã€‚
2ï¸âƒ£ å¦‚æœæ²¡æœ‰æ•°æ®ã€é—®é¢˜æ— è§„å¾‹ã€æˆ–é”™è¯¯é¢„æµ‹ä»£ä»·è¿‡é«˜ï¼ŒML å¯èƒ½ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚
3ï¸âƒ£ ML é€‚ç”¨äºå¤§è§„æ¨¡ã€é‡å¤æ€§ä»»åŠ¡ï¼Œå¹¶åœ¨æ•°æ®æ¨¡å¼å˜åŒ–æ—¶æ¯”ä¼ ç»Ÿè§„åˆ™ç³»ç»Ÿæ›´çµæ´»ï¼Œä½†ä»éœ€æƒè¡¡æˆæœ¬å’Œå¯è§£é‡Šæ€§ã€‚

ğŸ”¥ â€œå¦‚æœé¢è¯•å®˜é—®æˆ‘...â€ çš„æ–¹å¼å›é¡¾
â“ é¢è¯•å®˜é—® 1ï¼šä»€ä¹ˆæ—¶å€™åº”è¯¥ä½¿ç”¨æœºå™¨å­¦ä¹ ï¼Ÿ
âœ… å›ç­”ï¼š
æœºå™¨å­¦ä¹ é€‚ç”¨äºæ•°æ®é©±åŠ¨çš„é—®é¢˜ï¼Œå³ï¼š

æ•°æ®ä¸­å­˜åœ¨å¯å­¦ä¹ çš„æ¨¡å¼ï¼ˆå¦‚ Airbnb æˆ¿ä»·é¢„æµ‹ï¼‰ã€‚
æ‰‹å†™è§„åˆ™éš¾ä»¥åº”å¯¹å¤æ‚æƒ…å†µï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ï¼‰ã€‚
å¯ä»¥å¯¹æ–°æ•°æ®æ³›åŒ–ï¼Œé¢„æµ‹æœªçŸ¥æƒ…å†µã€‚
â“ é¢è¯•å®˜é—® 2ï¼šä»€ä¹ˆæ—¶å€™ä¸é€‚åˆä½¿ç”¨æœºå™¨å­¦ä¹ ï¼Ÿ
âœ… å›ç­”ï¼š
ML å¯èƒ½ä¸æ˜¯æœ€ä½³é€‰æ‹©çš„æƒ…å†µï¼š

é—®é¢˜æ— è§„å¾‹å¯å¾ªï¼ˆå¦‚æ·éª°å­ï¼‰ã€‚
å·²æœ‰ç®€å•è§„åˆ™å¯ä»¥è§£å†³ï¼ˆå¦‚è®¡ç®— 2+2ï¼‰ã€‚
é”™è¯¯é¢„æµ‹çš„æˆæœ¬å¤ªé«˜ï¼ˆå¦‚åŒ»ç–—è¯Šæ–­ï¼ŒAI é”™è¯¯å¯èƒ½å¯¼è‡´è¯¯è¯Šï¼‰ã€‚
â“ é¢è¯•å®˜é—® 3ï¼šML æ¯”ä¼ ç»Ÿæ–¹æ³•æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ
âœ… å›ç­”ï¼š

ML å¯ä»¥è‡ªåŠ¨å­¦ä¹ æ¨¡å¼ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•éœ€è¦æ‰‹åŠ¨ç¼–å†™è§„åˆ™ã€‚
ML é€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¦‚æœç´¢å¼•æ“ä¼˜åŒ–ï¼Œè€Œè§„åˆ™ç³»ç»Ÿéš¾ä»¥æ‰©å±•ã€‚
ML å¯ä»¥é€‚åº”å˜åŒ–ï¼Œå¦‚ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿï¼Œè€Œæ‰‹å†™è§„åˆ™éœ€è¦ä¸æ–­æ›´æ–°ã€‚

Ch1.2
ğŸ“Œ Key Takeaways (3-Sentence Summary)
1ï¸âƒ£ ML research focuses on SOTA performance, while production prioritizes speed, interpretability, and real-world constraints.
2ï¸âƒ£ Latency is a critical metric in ML systems, with percentiles (p50,p95, p99) offering a more reliable measurement than mean latency.
3ï¸âƒ£ Batch processing can increase inference latency, but is commonly used in large-scale distributed ML systems for efficiency.

ğŸ“Œ If an Interviewer Asks...
â“ Q1: Why is ML latency measurement important in production?
âœ… Answer:
Latency affects user experience and system performance. Mean latency can be misleading, so high percentiles (e.g., p95) help detect outliers and ensure real-world system reliability.

â“ Q2: Why does ML in production prioritize interpretability?
âœ… Answer:
Interpretability is essential for debugging, bias detection, and regulatory compliance. In high-stakes applications like loan approval and medical diagnosis, a black-box model is often unacceptable.

â“ Q3: How does batch processing affect ML inference?
âœ… Answer:
Batching improves computational efficiency, but introduces higher latency, since the system must wait for enough queries before processing them.


AIE ch1.1
ğŸ“Œ Key Takeaways (3-Sentence Summary)
1ï¸âƒ£ LLMs utilize self-supervised learning to process massive datasets, enhancing text-based AI applications.
2ï¸âƒ£ Foundational Models extend AI beyond text, enabling multimodal processing (text, images, audio, and video).
3ï¸âƒ£ To improve AI output, engineers leverage Prompt Engineering, RAG (retrieval-augmented generation), and fine-tuning.

ğŸ“Œ If an Interviewer Asks...
â“ Q1: How does an LLM differ from traditional language models?
âœ… Answer:
Traditional LMs predict missing words (Masked LM) or generate text sequentially (Auto-regressive LM), whereas LLMs handle longer dependencies, generate coherent responses, and can engage in interactive dialogue.

â“ Q2: What is the advantage of Foundational Models over LLMs?
âœ… Answer:
LLMs are text-only, whereas Foundational Models support multimodal inputs (text, images, audio, video), allowing AI to work across diverse domains like healthcare, robotics, and finance.

â“ Q3: How can an AI engineer improve a modelâ€™s performance?
âœ… Answer:

Prompt Engineering (optimize inputs for better model outputs).
RAG (Retrieval-Augmented Generation) (integrate external knowledge for more accurate responses).
Fine-Tuning (train models on domain-specific data for better specialization).

AIE ch1.2 
ğŸ“Œ Key Takeaways (3-Sentence Summary)
1ï¸âƒ£ Foundation models enable AI applications across diverse fields, including software development, content creation, customer service, and automation.
2ï¸âƒ£ AI-powered tools significantly enhance productivity, particularly in writing, coding, image/video production, and information aggregation.
3ï¸âƒ£ While AI offers incredible efficiency gains, ethical concerns (bias, misinformation, and automation risks) remain challenges that must be addressed.

ğŸ“Œ If an Interviewer Asks...
â“ Q1: What are the top use cases for Foundation Models in enterprises?
âœ… Answer:
Foundation Models are widely used in coding, writing, customer service, and workflow automation, enabling organizations to reduce costs, improve efficiency, and optimize business processes.

â“ Q2: How is AI impacting software engineering jobs?
âœ… Answer:
AI accelerates coding productivity but is less effective in highly complex tasks. It is expected to automate simple programming tasks while augmenting engineers rather than fully replacing them.

â“ Q3: What are the ethical concerns surrounding generative AI?
âœ… Answer:
AI raises concerns about content authenticity, misinformation, bias, and automation-related job losses, requiring responsible AI governance and oversight.




📌 优化后的总结
1️⃣ AI 工程师的崛起（The Rise of AI Engineer）
💡 为什么 AI 工程师变得重要？

语言模型（Language Models, LM）进化为大语言模型（LLM），使 AI 能够处理更复杂的任务。
LLM 的核心进步：自监督学习（Self-supervised Learning），使得模型可以利用更多数据进行训练，提高预测能力。
更大规模的参数 & 计算需求 → 需要 AI 工程师开发高效的基础设施，使 LLM 在企业中落地。
2️⃣ 语言模型的核心概念（From LM to LLM）
📌 什么是语言模型？

语言模型的目标是基于已有文本预测下一个 token，从而学习语言中的统计模式。
语言的最小处理单位是 token：
GPT-4 的 token 长度约为 一个单词的 ¾。
优点：
允许模型从单词的一部分中学习信息，提高泛化能力。
降低单词数量，使计算更高效。
处理 未知单词（OOV, Out of Vocabulary） 的能力更强。
📌 两种主要的语言模型架构：

类型	核心机制	代表模型	应用场景
Masked LM	随机遮盖句子中的某些单词，预测缺失部分	BERT	文本分类、情感分析、代码纠错
Auto-regressive LM	用 已有内容预测下一个 token	GPT 系列	文本生成、AI 写作、对话系统
💡 LLM vs 传统 LM：

普通语言模型 只能做文本预测，如 自动补全。
LLM（如 GPT）可以基于上下文生成更连贯的文本，但原始 LLM 不能像 ChatGPT 那样对话。
3️⃣ Foundational Models：超越文本，走向多模态
📌 为什么 LLM 发展成 Foundational Models？

传统语言模型 仅限于文本任务，但 AI 需要理解更多类型的数据（如图像、视频、音频）。
Foundational Models = General-Purpose Models（通用模型）
具备跨模态能力，支持 图像、声音、视频 处理。
📌 关键类别：

模型类型	能力	代表模型
LLM（大语言模型）	只处理文本	GPT-4, Claude 3
Multimodal Model（多模态模型）	处理 文本 + 图像	Gemini 1.5, GPT-4V, Flamingo
LMM（生成式多模态模型）	生成 文本+图像+视频	Stable Diffusion, DALL-E
Embedding 模型	生成向量表示，提高 AI 语义理解	OpenAI Embeddings, CLIP
4️⃣ 如何让 AI 生成你想要的结果？
📌 三种关键技术： 1️⃣ Prompt Engineering（提示工程）

通过优化提示词，提高 AI 生成内容的质量。
适用于：文本生成、代码生成、聊天机器人。
2️⃣ RAG（Retrieval-Augmented Generation）

结合外部知识库，让 AI 生成更精准的答案。
适用于：企业文档检索、智能客服、法律 & 医疗 AI。
3️⃣ Fine-tuning（微调）

让 AI 在特定任务上表现更好（例如法律 AI 需要学习专业文本）。
适用于：专业领域 NLP、自动驾驶、个性化推荐。
📌 实际应用：

企业 AI 工具（GitHub 上流行的 AI 工程工具）：
AutoGPT → 自动执行任务
Stable Diffusion Web UI → 生成 AI 图像
LangChain → 构建 LLM 应用
Ollama → 本地运行 LLM
